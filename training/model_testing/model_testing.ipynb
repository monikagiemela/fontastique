{"cells":[{"cell_type":"markdown","metadata":{"id":"2tW9V9M-RwMI"},"source":["## Testing prediction on a single picture"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"EKW0oMOWRqEz"},"outputs":[],"source":["from tensorflow import keras\n","import numpy as np\n","import tensorflow as tf\n","\n","from pathlib import Path \n","from PIL import Image\n","\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Load model"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"wWgllOHrR9Lw"},"outputs":[],"source":["model = keras.models.load_model(os.path.join(\"..\", \"app\", \"static\", \"top_model.h5\"))"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Optional function for resizing and changing to grayscale, but "]},{"cell_type":"code","execution_count":39,"metadata":{"id":"aS93NUlJSWzw"},"outputs":[],"source":["def resize_gray(img_path):\n","  img = Image.open(img_path).convert(\"L\")\n","  img.thumbnail((105,105))\n","  img.save(os.path.join(\"..\", \"app\", \"static\", \"uploads\", \"Aller_Lt_This_is_Fontastique.jpg\"))"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Run optional resizinng function"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["test_image = resize_gray(os.path.join(\"..\", \"app\", \"static\",\"output\", \"Aller_Lt\", \"This_is_Fontastique.jpg\"))"]},{"cell_type":"markdown","metadata":{},"source":["### 4. Get all font names"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ALYpsOdCVHul"},"outputs":[],"source":["class_names = os.listdir(os.path.join(\"..\", \"app\", \"static\", \"output\"))"]},{"cell_type":"markdown","metadata":{},"source":["### 5. Run prediction"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":651,"status":"ok","timestamp":1654963196580,"user":{"displayName":"Monika Giemela","userId":"08195882016517698556"},"user_tz":-120},"id":"G9BavT8KSt8v","outputId":"d6332862-110f-453b-f73f-aa2ddd0a25cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["This image most likely belongs to Raleway-Thin with a 2.32 percent confidence.\n"]}],"source":["img = tf.keras.utils.load_img(\n","    test_image, target_size=(105, 105)\n",")\n","img_array = tf.keras.utils.img_to_array(img)\n","img_array = tf.expand_dims(img_array, 0) # Create a batch\n","\n","predictions = model.predict(img_array)\n","score = tf.nn.softmax(predictions[0])\n","\n","print(\n","   f\"This image most likely belongs to {class_names[np.argmax(score)]} with a {100 * np.max(score):.2f} percent confidence.\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"RD3gajNUSyir"},"source":["TESTING SCORES:\n","\n","1. TRUE: This image most likely belongs to AllerDisplay with a 57.40 percent confidence.\n","2. This image most likely belongs to Raleway-ExtraLightItalic with a 99.98 percent confidence.\n","3. This image most likely belongs to Lato-Regular with a 96.64 percent confidence."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNofC1ZG3LtBLgLynkK7Tu1","name":"model_testing.ipynb","provenance":[{"file_id":"1Ps_iemEpLSEbhLE9kOFKZV0_LBs6wILt","timestamp":1651505313914}]},"kernelspec":{"display_name":"Python 3.10.0 ('env': venv)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.0"},"vscode":{"interpreter":{"hash":"0a6d7818407d7a8106f56bd37eea6f5bd69879797cbd7b3071c481beca4eea86"}}},"nbformat":4,"nbformat_minor":0}
